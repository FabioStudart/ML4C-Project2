Since the classes are unbalanced, we will calculate ROC-AUC metric to evaluate classifier performance. Okay?
-See Exploratory Data Analysis from part 1 for label histogram.

Due to seaborn version, heatmap figure is bad. Check if later we can use newer python and therefore update seaborn.
-See ClassicMachineLearning from part 1 for heatmap.

Performance of Random Forest and MLP classifiers is extremely high. I wasn't expecting it. I only trained kNN and NB later
to see if the task is easy or these classifiers are really good.

Could not use tsfresh correctly. Will move on to the RNN.

Dataset object was tested and works well. Realized data is already minmaxed. And in dataset, i do unsqueeze so the LSTM accepts my inputs.

RNN training and testing is implemented. However, output of LSTM is the same for all samples in validation set. I believe it is overfitting the majority class.
When I implement the dataloader that is balanced, it just predicts 0 for all.

Implemented Bidirectional LSTM. Same problem.

Will start with CNN.